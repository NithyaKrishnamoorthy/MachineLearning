{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn import linear_model,metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "\n",
    "dataset=pd.read_csv('bank-additional-full.csv',delimiter=';')\n",
    "dataset=pd.DataFrame(dataset)\n",
    "#remove rows with value 'unknown'\n",
    "dataset.drop(['duration'],axis=1,inplace=True)\n",
    "dataset['y']=dataset['y'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting unknowns for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column job has 330 of unknown values.\n",
      "column marital has 80 of unknown values.\n",
      "column education has 1731 of unknown values.\n",
      "column default has 8597 of unknown values.\n",
      "column housing has 990 of unknown values.\n",
      "column loan has 990 of unknown values.\n",
      "column contact has 0 of unknown values.\n",
      "column month has 0 of unknown values.\n",
      "column day_of_week has 0 of unknown values.\n",
      "column poutcome has 0 of unknown values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "col_name=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "for item in col_name:\n",
    "    col=dataset[item].as_matrix()\n",
    "    count_unkown=0\n",
    "    for i in range(col.shape[0]):\n",
    "        if col[i]=='unknown':\n",
    "            count_unkown+=1    \n",
    "    print('column',item,'has',count_unkown,'of unknown values.')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the unknown values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30488, 20)\n"
     ]
    }
   ],
   "source": [
    "dataset=dataset[(dataset['job']!='unknown')&(dataset['marital']!='unknown')&(dataset['education']!='unknown')&(dataset['default']!='unknown')&(dataset['housing']!='unknown')&(dataset['loan']!='unknown')]\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert categorical values to encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30488, 20)\n",
      "       age  job  marital  education  default  housing  loan  contact  month  \\\n",
      "0       56    3        1          0        0        0     0        1      6   \n",
      "2       37    7        1          3        0        1     0        1      6   \n",
      "3       40    0        1          1        0        0     0        1      6   \n",
      "4       56    7        1          3        0        0     1        1      6   \n",
      "6       59    0        1          5        0        0     0        1      6   \n",
      "8       24    9        2          5        0        1     0        1      6   \n",
      "9       25    7        2          3        0        1     0        1      6   \n",
      "11      25    7        2          3        0        1     0        1      6   \n",
      "12      29    1        2          3        0        0     1        1      6   \n",
      "13      57    3        0          0        0        1     0        1      6   \n",
      "14      35    1        1          1        0        1     0        1      6   \n",
      "16      35    1        1          1        0        1     0        1      6   \n",
      "18      50    1        1          2        0        1     1        1      6   \n",
      "20      30   10        1          3        0        0     0        1      6   \n",
      "22      55    5        2          3        0        1     0        1      6   \n",
      "23      41    9        2          3        0        1     0        1      6   \n",
      "24      37    0        1          3        0        1     0        1      6   \n",
      "25      35    9        1          6        0        0     1        1      6   \n",
      "34      54    1        0          0        0        0     0        1      6   \n",
      "36      34    7        1          3        0        0     0        1      6   \n",
      "37      52    9        1          2        0        1     0        1      6   \n",
      "38      41    0        1          6        0        1     0        1      6   \n",
      "39      56    9        1          0        0        1     0        1      6   \n",
      "41      32    2        1          3        0        1     0        1      6   \n",
      "42      38    0        2          5        0        0     0        1      6   \n",
      "43      57    0        1          6        0        0     1        1      6   \n",
      "46      57    0        1          6        0        1     1        1      6   \n",
      "47      40    1        1          2        0        0     1        1      6   \n",
      "48      35    0        1          6        0        1     0        1      6   \n",
      "49      45    1        1          2        0        1     0        1      6   \n",
      "...    ...  ...      ...        ...      ...      ...   ...      ...    ...   \n",
      "41157   31    3        2          6        0        0     0        0      7   \n",
      "41158   35    9        0          0        0        0     0        0      7   \n",
      "41159   35    9        0          0        0        1     0        0      7   \n",
      "41160   33    0        1          6        0        0     0        0      7   \n",
      "41161   33    0        1          6        0        1     0        0      7   \n",
      "41162   60    1        1          0        0        1     0        0      7   \n",
      "41163   35    9        0          0        0        1     0        0      7   \n",
      "41164   54    0        1          5        0        0     0        0      7   \n",
      "41165   38    3        0          6        0        0     0        0      7   \n",
      "41166   32    0        1          6        0        0     0        1      7   \n",
      "41167   32    0        1          6        0        1     0        0      7   \n",
      "41168   38    2        1          6        0        0     0        0      7   \n",
      "41169   62    7        1          3        0        1     0        0      7   \n",
      "41170   40    4        0          6        0        1     0        0      7   \n",
      "41171   33    8        1          5        0        1     0        1      7   \n",
      "41172   31    0        2          6        0        1     0        0      7   \n",
      "41173   62    5        1          6        0        1     0        0      7   \n",
      "41174   62    5        1          6        0        1     0        0      7   \n",
      "41176   38    3        0          3        0        1     1        0      7   \n",
      "41177   57    5        1          5        0        1     0        0      7   \n",
      "41178   62    5        1          6        0        0     0        0      7   \n",
      "41179   64    5        0          5        0        1     0        0      7   \n",
      "41180   36    0        1          6        0        0     0        0      7   \n",
      "41181   37    0        1          6        0        1     0        0      7   \n",
      "41182   29   10        2          0        0        1     0        0      7   \n",
      "41183   73    5        1          5        0        1     0        0      7   \n",
      "41184   46    1        1          5        0        0     0        0      7   \n",
      "41185   56    5        1          6        0        1     0        0      7   \n",
      "41186   44    9        1          5        0        0     0        0      7   \n",
      "41187   74    5        1          5        0        1     0        0      7   \n",
      "\n",
      "       day_of_week  campaign  pdays  previous  poutcome  emp.var.rate  \\\n",
      "0                1         1    999         0         1           1.1   \n",
      "2                1         1    999         0         1           1.1   \n",
      "3                1         1    999         0         1           1.1   \n",
      "4                1         1    999         0         1           1.1   \n",
      "6                1         1    999         0         1           1.1   \n",
      "8                1         1    999         0         1           1.1   \n",
      "9                1         1    999         0         1           1.1   \n",
      "11               1         1    999         0         1           1.1   \n",
      "12               1         1    999         0         1           1.1   \n",
      "13               1         1    999         0         1           1.1   \n",
      "14               1         1    999         0         1           1.1   \n",
      "16               1         1    999         0         1           1.1   \n",
      "18               1         1    999         0         1           1.1   \n",
      "20               1         1    999         0         1           1.1   \n",
      "22               1         1    999         0         1           1.1   \n",
      "23               1         1    999         0         1           1.1   \n",
      "24               1         1    999         0         1           1.1   \n",
      "25               1         1    999         0         1           1.1   \n",
      "34               1         1    999         0         1           1.1   \n",
      "36               1         1    999         0         1           1.1   \n",
      "37               1         1    999         0         1           1.1   \n",
      "38               1         1    999         0         1           1.1   \n",
      "39               1         1    999         0         1           1.1   \n",
      "41               1         1    999         0         1           1.1   \n",
      "42               1         1    999         0         1           1.1   \n",
      "43               1         1    999         0         1           1.1   \n",
      "46               1         1    999         0         1           1.1   \n",
      "47               1         1    999         0         1           1.1   \n",
      "48               1         1    999         0         1           1.1   \n",
      "49               1         2    999         0         1           1.1   \n",
      "...            ...       ...    ...       ...       ...           ...   \n",
      "41157            1         4    999         0         1          -1.1   \n",
      "41158            3         1    999         0         1          -1.1   \n",
      "41159            3         1      9         4         2          -1.1   \n",
      "41160            3         1    999         0         1          -1.1   \n",
      "41161            3         1    999         1         0          -1.1   \n",
      "41162            3         2      4         1         2          -1.1   \n",
      "41163            3         3      4         2         2          -1.1   \n",
      "41164            3         2     10         1         2          -1.1   \n",
      "41165            4         2    999         0         1          -1.1   \n",
      "41166            4         1    999         1         0          -1.1   \n",
      "41167            4         3    999         0         1          -1.1   \n",
      "41168            4         2    999         0         1          -1.1   \n",
      "41169            4         5    999         0         1          -1.1   \n",
      "41170            4         2    999         4         0          -1.1   \n",
      "41171            2         1    999         0         1          -1.1   \n",
      "41172            2         1    999         0         1          -1.1   \n",
      "41173            2         1    999         2         0          -1.1   \n",
      "41174            2         1      1         6         2          -1.1   \n",
      "41176            2         1    999         0         1          -1.1   \n",
      "41177            2         6    999         0         1          -1.1   \n",
      "41178            2         2      6         3         2          -1.1   \n",
      "41179            0         3    999         0         1          -1.1   \n",
      "41180            0         2    999         0         1          -1.1   \n",
      "41181            0         1    999         0         1          -1.1   \n",
      "41182            0         1      9         1         2          -1.1   \n",
      "41183            0         1    999         0         1          -1.1   \n",
      "41184            0         1    999         0         1          -1.1   \n",
      "41185            0         2    999         0         1          -1.1   \n",
      "41186            0         1    999         0         1          -1.1   \n",
      "41187            0         3    999         1         0          -1.1   \n",
      "\n",
      "       cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
      "0              93.994          -36.4      4.857       5191.0  0  \n",
      "2              93.994          -36.4      4.857       5191.0  0  \n",
      "3              93.994          -36.4      4.857       5191.0  0  \n",
      "4              93.994          -36.4      4.857       5191.0  0  \n",
      "6              93.994          -36.4      4.857       5191.0  0  \n",
      "8              93.994          -36.4      4.857       5191.0  0  \n",
      "9              93.994          -36.4      4.857       5191.0  0  \n",
      "11             93.994          -36.4      4.857       5191.0  0  \n",
      "12             93.994          -36.4      4.857       5191.0  0  \n",
      "13             93.994          -36.4      4.857       5191.0  0  \n",
      "14             93.994          -36.4      4.857       5191.0  0  \n",
      "16             93.994          -36.4      4.857       5191.0  0  \n",
      "18             93.994          -36.4      4.857       5191.0  0  \n",
      "20             93.994          -36.4      4.857       5191.0  0  \n",
      "22             93.994          -36.4      4.857       5191.0  0  \n",
      "23             93.994          -36.4      4.857       5191.0  0  \n",
      "24             93.994          -36.4      4.857       5191.0  0  \n",
      "25             93.994          -36.4      4.857       5191.0  0  \n",
      "34             93.994          -36.4      4.857       5191.0  0  \n",
      "36             93.994          -36.4      4.857       5191.0  0  \n",
      "37             93.994          -36.4      4.857       5191.0  0  \n",
      "38             93.994          -36.4      4.857       5191.0  0  \n",
      "39             93.994          -36.4      4.857       5191.0  0  \n",
      "41             93.994          -36.4      4.857       5191.0  0  \n",
      "42             93.994          -36.4      4.857       5191.0  0  \n",
      "43             93.994          -36.4      4.857       5191.0  0  \n",
      "46             93.994          -36.4      4.857       5191.0  0  \n",
      "47             93.994          -36.4      4.857       5191.0  0  \n",
      "48             93.994          -36.4      4.857       5191.0  0  \n",
      "49             93.994          -36.4      4.857       5191.0  0  \n",
      "...               ...            ...        ...          ... ..  \n",
      "41157          94.767          -50.8      1.039       4963.6  0  \n",
      "41158          94.767          -50.8      1.035       4963.6  1  \n",
      "41159          94.767          -50.8      1.035       4963.6  1  \n",
      "41160          94.767          -50.8      1.035       4963.6  1  \n",
      "41161          94.767          -50.8      1.035       4963.6  0  \n",
      "41162          94.767          -50.8      1.035       4963.6  0  \n",
      "41163          94.767          -50.8      1.035       4963.6  1  \n",
      "41164          94.767          -50.8      1.035       4963.6  1  \n",
      "41165          94.767          -50.8      1.030       4963.6  1  \n",
      "41166          94.767          -50.8      1.030       4963.6  1  \n",
      "41167          94.767          -50.8      1.030       4963.6  0  \n",
      "41168          94.767          -50.8      1.030       4963.6  0  \n",
      "41169          94.767          -50.8      1.030       4963.6  0  \n",
      "41170          94.767          -50.8      1.030       4963.6  0  \n",
      "41171          94.767          -50.8      1.031       4963.6  1  \n",
      "41172          94.767          -50.8      1.031       4963.6  1  \n",
      "41173          94.767          -50.8      1.031       4963.6  1  \n",
      "41174          94.767          -50.8      1.031       4963.6  1  \n",
      "41176          94.767          -50.8      1.031       4963.6  0  \n",
      "41177          94.767          -50.8      1.031       4963.6  0  \n",
      "41178          94.767          -50.8      1.031       4963.6  1  \n",
      "41179          94.767          -50.8      1.028       4963.6  0  \n",
      "41180          94.767          -50.8      1.028       4963.6  0  \n",
      "41181          94.767          -50.8      1.028       4963.6  1  \n",
      "41182          94.767          -50.8      1.028       4963.6  0  \n",
      "41183          94.767          -50.8      1.028       4963.6  1  \n",
      "41184          94.767          -50.8      1.028       4963.6  0  \n",
      "41185          94.767          -50.8      1.028       4963.6  0  \n",
      "41186          94.767          -50.8      1.028       4963.6  1  \n",
      "41187          94.767          -50.8      1.028       4963.6  0  \n",
      "\n",
      "[30488 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "categorical_col=['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']\n",
    "for item in categorical_col:\n",
    "    dataset[item]=dataset[item].astype('category')\n",
    "cat_columns = dataset.select_dtypes(['category']).columns\n",
    "dataset[cat_columns] = dataset[cat_columns].apply(lambda x: x.cat.codes)\n",
    "print(dataset.shape)\n"
	]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downsampling the majority class to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3859, 20)\n",
      "(6785, 20)\n",
      "(10644, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "dataset_classyes=dataset[dataset['y']==1].as_matrix()\n",
    "dataset_classno=dataset[dataset['y']==0].as_matrix()\n",
    "\n",
    "sample=np.random.choice([True, False], len(dataset_classno), replace=True, p=[0.25, 0.75])\n",
    "#downsample dataset with class value 'no' \n",
    "dataset_classno_downsampled=dataset_classno[sample]\n",
    "print(dataset_classyes.shape)\n",
    "print(dataset_classno_downsampled.shape)\n",
    "\n",
    "final=np.concatenate((dataset_classno_downsampled,dataset_classyes),axis=0)\n",
    "print(final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=final[:,:-1]\n",
    "y=final[:,-1]\n",
    "fit_rf=RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters using grid search: \n",
      " {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "param_dist = {'max_depth':[2,3,4],\n",
    "              #'n_estimators':[10,50,100],\n",
    "             'bootstrap':[True, False],\n",
    "             'max_features':['auto','sqrt','log2',None],\n",
    "             'criterion':['gini','entropy']}\n",
    "\n",
    "cv_rf = GridSearchCV(fit_rf,cv=10,param_grid=param_dist,n_jobs=3)\n",
    "\n",
    "cv_rf.fit(x,y)\n",
    "\n",
    "print('Best parameters using grid search: \\n',\n",
    "     cv_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run classifier for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. The feature nr.employed with index 18 has a mean decrease in impurity of 0.30857\n",
      "2. The feature euribor3m with index 17 has a mean decrease in impurity of 0.17999\n",
      "3. The feature emp.var.rate with index 14 has a mean decrease in impurity of 0.12911\n",
      "4. The feature pdays with index 11 has a mean decrease in impurity of 0.12903\n",
      "5. The feature poutcome with index 13 has a mean decrease in impurity of 0.08117\n",
      "6. The feature cons.conf.idx with index 16 has a mean decrease in impurity of 0.07517\n",
      "7. The feature previous with index 12 has a mean decrease in impurity of 0.02714\n",
      "8. The feature contact with index 7 has a mean decrease in impurity of 0.02144\n",
      "9. The feature month with index 8 has a mean decrease in impurity of 0.01771\n",
      "10. The feature cons.price.idx with index 15 has a mean decrease in impurity of 0.01720\n",
      "11. The feature age with index 0 has a mean decrease in impurity of 0.01117\n",
      "12. The feature campaign with index 10 has a mean decrease in impurity of 0.00191\n",
      "13. The feature day_of_week with index 9 has a mean decrease in impurity of 0.00029\n",
      "14. The feature marital with index 2 has a mean decrease in impurity of 0.00004\n",
      "15. The feature education with index 3 has a mean decrease in impurity of 0.00004\n",
      "16. The feature job with index 1 has a mean decrease in impurity of 0.00001\n",
      "17. The feature loan with index 6 has a mean decrease in impurity of 0.00000\n",
      "18. The feature housing with index 5 has a mean decrease in impurity of 0.00000\n",
      "19. The feature default with index 4 has a mean decrease in impurity of 0.00000\n"
     ]
    }
   ],
   "source": [
    "fit_rf.set_params(criterion='entropy',n_estimators = 100,max_features='auto',max_depth=2,bootstrap=False)\n",
    "fit_rf.fit(x,y)\n",
    "\n",
    "def variable_importance(fit):\n",
    "    importances = fit.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    return {'importance':importances,'index':indices}\n",
    "\n",
    "var_imp_rf=variable_importance(fit_rf)\n",
    "importances_rf=var_imp_rf['importance']\n",
    "indices_rf=var_imp_rf['index']\n",
    "\n",
    "print('Feature ranking:')\n",
    "feature_name=['age','job','marital','education','default','housing','loan','contact','month','day_of_week',\n",
    "              'campaign','pdays','previous','poutcome','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "\n",
    "\n",
    "for i in range(0,indices_rf.shape[0]):\n",
    "    f = i\n",
    "    print('{0}. The feature {1} with index {3} has a mean decrease in impurity of {2:.5f}'.format(f+1,feature_name[indices_rf[i]],importances_rf[indices_rf[f]],indices_rf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10644, 20)\n",
      "(6376, 20)\n",
      "(4268, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "print(final.shape)\n",
    "names = dataset.columns.values\n",
    "finaldf = pd.DataFrame(data=final,columns=names)\n",
    "\n",
    "np.random.seed(2018)\n",
    "train = np.random.choice([True, False], finaldf.shape[0], replace=True, p=[0.6, 0.4])\n",
    "\n",
    "\n",
    "bank_train = finaldf.iloc[train,:].as_matrix()\n",
    "bank_test = finaldf.iloc[~train,:].as_matrix()\n",
    "\n",
    "print(bank_train.shape)\n",
    "print(bank_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select top 3 features for Logistic regression and Naive Bayes classifier:<br>\n",
    "<ol>\n",
    "    <li>nr.employed (index 18)</li>\n",
    "    <li>euribor3m (index 17)</li>\n",
    "    <li>emp.var.rate (index 14)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for test data for logistic regression 18 17 is 0.7188378631677601\n",
      "F1 for logistic regression is  0.6583143507972665\n",
      "precision and recall for Naive Bayes classifier 18 17 : 0.5892678034102307 0.7619974059662775\n",
      "f1 score for Naive Bayes classifiern is  0.6645927601809954\n",
      "accuracy for test data for logistic regression 18 14 is 0.700796626054358\n",
      "F1 for logistic regression is  0.6245221993531314\n",
      "precision and recall for Naive Bayes classifier 18 14 : 0.5892678034102307 0.7619974059662775\n",
      "f1 score for Naive Bayes classifiern is  0.6645927601809954\n",
      "accuracy for test data for logistic regression 17 14 is 0.7207122774133083\n",
      "F1 for logistic regression is  0.6623229461756374\n",
      "precision and recall for Naive Bayes classifier 17 14 : 0.5892678034102307 0.7619974059662775\n",
      "f1 score for Naive Bayes classifiern is  0.6645927601809954\n",
      "accuracy for test data for logistic regression 18 17 14 is 0.7221180880974696\n",
      "F1 is  0.6645927601809954\n",
      "precision and recall for Naive Bayes classifier 18 17 : 0.5892678034102307 0.7619974059662775\n",
      "f1 score for Naive Bayes classifiern is  0.6645927601809954\n"
     ]
    }
   ],
   "source": [
    "top = [18,17,14]\n",
    "\n",
    "logit = linear_model.LogisticRegression()\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "\n",
    "#2 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        x_train = bank_train[:,[top[i],top[j]]].astype(float)\n",
    "        y_train = bank_train[:,19].astype(float)\n",
    "        \n",
    "        x_test = bank_test[:,[top[i],top[j]]].astype(float)\n",
    "        y_test = bank_test[:,19].astype(float)\n",
    "       \n",
    "        \n",
    "        logit.fit(x_train, y_train)\n",
    "        y_test_pred = logit.predict(x_test)\n",
    "        \n",
    "        gnb.fit(x_train, y_train)\n",
    "        y_pred1 = gnb.predict(x_test)\n",
    "            \n",
    "        print('accuracy for test data for logistic regression',top[i],top[j],'is' , metrics.accuracy_score(y_test, y_test_pred))\n",
    "        print('F1 for logistic regression is ' , f1_score(y_test, y_test_pred))\n",
    "        \n",
    "        print('precision and recall for Naive Bayes classifier',top[i], top[j],':', metrics.precision_score(y_test, y_pred1), metrics.recall_score(y_test, y_pred1))\n",
    "        print('f1 score for Naive Bayes classifiern is ', f1_score(y_test,y_pred1))\n",
    "\n",
    "#3 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        for k in range(j+1,3):\n",
    "            x_train = bank_train[:,[top[i],top[j],top[k]]].astype(float)\n",
    "            y_train = bank_train[:,19].astype(float)\n",
    "            \n",
    "            x_test = bank_test[:,[top[i],top[j],top[k]]].astype(float)\n",
    "            y_test = bank_test[:,19].astype(float)\n",
    "            \n",
    "            \n",
    "            logit.fit(x_train, y_train)\n",
    "            y_test_pred = logit.predict(x_test)\n",
    "\n",
    "            gnb.fit(x_train, y_train)\n",
    "            y_pred1 = gnb.predict(x_test)\n",
    "        \n",
    "            print('accuracy for test data for logistic regression',top[i],top[j],top[k],'is' , metrics.accuracy_score(y_test, y_test_pred))\n",
    "            print('F1 is ' , f1_score(y_test, y_test_pred))\n",
    "            \n",
    "            print('precision and recall for Naive Bayes classifier',top[i], top[j],':', metrics.precision_score(y_test, y_pred1), metrics.recall_score(y_test, y_pred1))\n",
    "            print('f1 score for Naive Bayes classifiern is ', f1_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on whole dataset (Only the best score with different C number and Linear/RBF model is selected for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Linear SVM with 2 features , 18 17 and with C number  1  is  0.7221180880974696\n",
      "F1 score for Linear SVM with 2 features, 18 17 and with C number  1  is  0.6645927601809954\n",
      "Classification report for Linear SVM with 2 features, 18 17 and with C number  1 is               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.70      0.76      2726\n",
      "        1.0       0.59      0.76      0.66      1542\n",
      "\n",
      "avg / total       0.75      0.72      0.73      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Linear SVM with 2 features , 18 17 and with C number  10  is  0.7221180880974696\n",
      "F1 score for Linear SVM with 2 features, 18 17 and with C number  10  is  0.6645927601809954\n",
      "Classification report for Linear SVM with 2 features, 18 17 and with C number  10 is               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.70      0.76      2726\n",
      "        1.0       0.59      0.76      0.66      1542\n",
      "\n",
      "avg / total       0.75      0.72      0.73      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Linear SVM with 2 features , 18 14 and with C number  1  is  0.4055763823805061\n",
      "F1 score for Linear SVM with 2 features, 18 14 and with C number  1  is  0.3463024993558362\n",
      "Classification report for Linear SVM with 2 features, 18 14 and with C number  1 is               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.39      0.45      2726\n",
      "        1.0       0.29      0.44      0.35      1542\n",
      "\n",
      "avg / total       0.45      0.41      0.42      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Linear SVM with 2 features , 18 14 and with C number  10  is  0.4055763823805061\n",
      "F1 score for Linear SVM with 2 features, 18 14 and with C number  10  is  0.3463024993558362\n",
      "Classification report for Linear SVM with 2 features, 18 14 and with C number  10 is               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.55      0.39      0.45      2726\n",
      "        1.0       0.29      0.44      0.35      1542\n",
      "\n",
      "avg / total       0.45      0.41      0.42      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Linear SVM with 2 features , 17 14 and with C number  1  is  0.7221180880974696\n",
      "F1 score for Linear SVM with 2 features, 17 14 and with C number  1  is  0.6645927601809954\n",
      "Classification report for Linear SVM with 2 features, 17 14 and with C number  1 is               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.70      0.76      2726\n",
      "        1.0       0.59      0.76      0.66      1542\n",
      "\n",
      "avg / total       0.75      0.72      0.73      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Linear SVM with 2 features , 17 14 and with C number  10  is  0.7221180880974696\n",
      "F1 score for Linear SVM with 2 features, 17 14 and with C number  10  is  0.6645927601809954\n",
      "Classification report for Linear SVM with 2 features, 17 14 and with C number  10 is               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.70      0.76      2726\n",
      "        1.0       0.59      0.76      0.66      1542\n",
      "\n",
      "avg / total       0.75      0.72      0.73      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [18,17,14]\n",
    "\n",
    "#Linear Kernel\n",
    "    \n",
    "#2 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        x_train = bank_train[:,[top[i],top[j]]].astype(float)\n",
    "        y_train = bank_train[:,19].astype(float)\n",
    "\n",
    "        x_test = bank_test[:,[top[i],top[j]]].astype(float)\n",
    "        y_test = bank_test[:,19].astype(float)\n",
    "\n",
    "        clf=[]\n",
    "        for C in [1,10]:\n",
    "            \n",
    "            clf = svm.SVC(kernel='linear', C=C)\n",
    "            clf.fit(x_train, y_train)\n",
    "            predicted = clf.predict(x_test)\n",
    "            print (\"Accuracy score for Linear SVM with 2 features ,\", top[i],top[j],\"and with C number \",C,\" is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "            print (\"F1 score for Linear SVM with 2 features,\", top[i],top[j],\"and with C number \",C,\" is \" ,metrics.f1_score(y_test, predicted))\n",
    "            print(\"Classification report for Linear SVM with 2 features,\", top[i],top[j],\"and with C number \",C,\"is \",classification_report(y_test, predicted))\n",
    "            print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Linear SVM with 3 features with C number  1  is  0.7626522961574508\n",
      "F1 score for Linear SVM with 3 features with C number  1   is  0.6041422430636968\n",
      "Classification report for Linear SVM with 3 features with C number  1  is:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.91      0.83      2726\n",
      "        1.0       0.76      0.50      0.60      1542\n",
      "\n",
      "avg / total       0.76      0.76      0.75      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for Linear SVM with 3 features with C number  10  is  0.7626522961574508\n",
      "F1 score for Linear SVM with 3 features with C number  10   is  0.6041422430636968\n",
      "Classification report for Linear SVM with 3 features with C number  10  is:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.91      0.83      2726\n",
      "        1.0       0.76      0.50      0.60      1542\n",
      "\n",
      "avg / total       0.76      0.76      0.75      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [18,17,14]\n",
    "\n",
    "#Linear Kernel\n",
    "\n",
    "#3 features:\n",
    "\n",
    "x_train = bank_train[:,[18,17,14]].astype(float)\n",
    "y_train = bank_train[:,19].astype(float)\n",
    "\n",
    "x_test = bank_test[:,[18,17,14]].astype(float)\n",
    "y_test = bank_test[:,19].astype(float)\n",
    "\n",
    "clf=[]\n",
    "for C in [1,10]:\n",
    "    clf = svm.SVC(kernel='linear', C=C)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "    \n",
    "    print (\"Accuracy score for Linear SVM with 3 features with C number \",C,\" is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "    print (\"F1 score for Linear SVM with 3 features with C number \",C,\"  is \" ,metrics.f1_score(y_test, predicted))\n",
    "    print(\"Classification report for Linear SVM with 3 features with C number \",C,\" is: \",classification_report(y_test, predicted))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM with RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for RBF SVM with 2 features , 18 17 and with C number  1   is  0.7703842549203374\n",
      "F1 score for RBF SVM with 2 features , 18 17 and with C number  1   is  0.6242331288343559\n",
      "Classification report for RBF SVM with 2 features , 18 17 and with C number  1  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.91      0.83      2726\n",
      "        1.0       0.76      0.53      0.62      1542\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 2 features , 18 17 and with C number  10   is  0.7696813495782568\n",
      "F1 score for RBF SVM with 2 features , 18 17 and with C number  10   is  0.6235158942933742\n",
      "Classification report for RBF SVM with 2 features , 18 17 and with C number  10  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.91      0.83      2726\n",
      "        1.0       0.76      0.53      0.62      1542\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 2 features , 18 14 and with C number  1   is  0.7626522961574508\n",
      "F1 score for RBF SVM with 2 features , 18 14 and with C number  1   is  0.6041422430636968\n",
      "Classification report for RBF SVM with 2 features , 18 14 and with C number  1  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.91      0.83      2726\n",
      "        1.0       0.76      0.50      0.60      1542\n",
      "\n",
      "avg / total       0.76      0.76      0.75      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 2 features , 18 14 and with C number  10   is  0.7626522961574508\n",
      "F1 score for RBF SVM with 2 features , 18 14 and with C number  10   is  0.6041422430636968\n",
      "Classification report for RBF SVM with 2 features , 18 14 and with C number  10  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.76      0.91      0.83      2726\n",
      "        1.0       0.76      0.50      0.60      1542\n",
      "\n",
      "avg / total       0.76      0.76      0.75      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 2 features , 17 14 and with C number  1   is  0.7678069353327085\n",
      "F1 score for RBF SVM with 2 features , 17 14 and with C number  1   is  0.6166344294003869\n",
      "Classification report for RBF SVM with 2 features , 17 14 and with C number  1  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.91      0.83      2726\n",
      "        1.0       0.76      0.52      0.62      1542\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 2 features , 17 14 and with C number  10   is  0.7701499531396439\n",
      "F1 score for RBF SVM with 2 features , 17 14 and with C number  10   is  0.6239938673821388\n",
      "Classification report for RBF SVM with 2 features , 17 14 and with C number  10  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.91      0.83      2726\n",
      "        1.0       0.76      0.53      0.62      1542\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [18,17,14]\n",
    "\n",
    "#RBF Kernel\n",
    "   \n",
    "#2 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        x_train = bank_train[:,[top[i],top[j]]].astype(float)\n",
    "        y_train = bank_train[:,19].astype(float)\n",
    "\n",
    "        x_test = bank_test[:,[top[i],top[j]]].astype(float)\n",
    "        y_test = bank_test[:,19].astype(float)\n",
    "\n",
    "        clf=[]\n",
    "        for C in [1,10]:\n",
    "            \n",
    "            clf = svm.SVC(kernel='rbf', C=C)\n",
    "            clf.fit(x_train, y_train)\n",
    "            predicted = clf.predict(x_test)\n",
    "           \n",
    "            print (\"Accuracy score for RBF SVM with 2 features ,\", top[i],top[j],\"and with C number \",C,\"  is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "            print (\"F1 score for RBF SVM with 2 features ,\", top[i],top[j],\"and with C number \",C,\"  is \" ,metrics.f1_score(y_test, predicted))\n",
    "            print(\"Classification report for RBF SVM with 2 features ,\", top[i],top[j],\"and with C number \",C,\" : \",classification_report(y_test, predicted))\n",
    "            print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for RBF SVM with 3 features with C number  1  is  0.7678069353327085\n",
      "F1 score for RBF SVM with 3 features with C number  1   is  0.6166344294003869\n",
      "Classification report for RBF SVM with 3 features with C number  1  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.91      0.83      2726\n",
      "        1.0       0.76      0.52      0.62      1542\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 3 features with C number  10  is  0.7703842549203374\n",
      "F1 score for RBF SVM with 3 features with C number  10   is  0.6242331288343559\n",
      "Classification report for RBF SVM with 3 features with C number  10  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.91      0.83      2726\n",
      "        1.0       0.76      0.53      0.62      1542\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 3 features with C number  100  is  0.770618556701031\n",
      "F1 score for RBF SVM with 3 features with C number  100   is  0.6264784433422358\n",
      "Classification report for RBF SVM with 3 features with C number  100  :               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.77      0.91      0.83      2726\n",
      "        1.0       0.76      0.53      0.63      1542\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [18,17,14]\n",
    "\n",
    "#rbf Kernel\n",
    "    \n",
    "#3 features:\n",
    "\n",
    "x_train = bank_train[:,[18,17,14]].astype(float)\n",
    "y_train = bank_train[:,19].astype(float)\n",
    "\n",
    "x_test = bank_test[:,[18,17,14]].astype(float)\n",
    "y_test = bank_test[:,19].astype(float)\n",
    "\n",
    "clf=[]\n",
    "for C in [1,10,100]:\n",
    "    clf = svm.SVC(kernel='rbf', C=C)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "    \n",
    "    print (\"Accuracy score for RBF SVM with 3 features with C number \",C,\" is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "    print (\"F1 score for RBF SVM with 3 features with C number \",C,\"  is \" ,metrics.f1_score(y_test, predicted))\n",
    "    print(\"Classification report for RBF SVM with 3 features with C number \",C,\" : \",classification_report(y_test, predicted))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal = finaldf.copy()\n",
    "personal.drop(['contact','month','day_of_week','campaign','pdays','previous','poutcome','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed',],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters using grid search: \n",
      " {'bootstrap': False, 'criterion': 'entropy', 'max_depth': 4, 'max_features': None}\n"
     ]
    }
   ],
   "source": [
    "x=personal.iloc[:,:-1]\n",
    "y=personal.iloc[:,-1]\n",
    "fit_rf=RandomForestClassifier(random_state=0)\n",
    "\n",
    "np.random.seed(0)\n",
    "param_dist = {'max_depth':[2,3,4],\n",
    "             'bootstrap':[True, False],\n",
    "             'max_features':['auto','sqrt','log2',None],\n",
    "             'criterion':['gini','entropy']}\n",
    "\n",
    "cv_rf = GridSearchCV(fit_rf,cv=10,param_grid=param_dist,n_jobs=3)\n",
    "\n",
    "cv_rf.fit(x,y)\n",
    "\n",
    "print('Best parameters using grid search: \\n',\n",
    "     cv_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. The feature age with index 0 has a mean decrease in impurity of 0.62202\n",
      "2. The feature education with index 3 has a mean decrease in impurity of 0.15322\n",
      "3. The feature job with index 1 has a mean decrease in impurity of 0.14183\n",
      "4. The feature marital with index 2 has a mean decrease in impurity of 0.07376\n",
      "5. The feature housing with index 5 has a mean decrease in impurity of 0.00580\n",
      "6. The feature loan with index 6 has a mean decrease in impurity of 0.00337\n",
      "7. The feature default with index 4 has a mean decrease in impurity of 0.00000\n"
     ]
    }
   ],
   "source": [
    "fit_rf.set_params(criterion='entropy',n_estimators = 100,max_features='auto',max_depth=4,bootstrap=False)\n",
    "fit_rf.fit(x,y)\n",
    "\n",
    "def variable_importance(fit):\n",
    "    importances = fit.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    return {'importance':importances,'index':indices}\n",
    "\n",
    "var_imp_rf=variable_importance(fit_rf)\n",
    "importances_rf=var_imp_rf['importance']\n",
    "indices_rf=var_imp_rf['index']\n",
    "\n",
    "print('Feature ranking:')\n",
    "feature_name=['age','job','marital','education','default','housing','loan']\n",
    "\n",
    "\n",
    "for i in range(0,indices_rf.shape[0]):\n",
    "    f = i\n",
    "    print('{0}. The feature {1} with index {3} has a mean decrease in impurity of {2:.5f}'.format(f+1,feature_name[indices_rf[i]],importances_rf[indices_rf[f]],indices_rf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for test data for logistic regression 0 3 is 0.6408153701968134\n",
      "F1 for logistic regression is  0.017937219730941707\n",
      "precision and recall for Naive Bayes classifier 0 3 : 0.5748663101604278 0.13942931258106356\n",
      "f1 score for Naive Bayes classifiern is  0.22442588726513568\n",
      "accuracy for test data for logistic regression 0 1 is 0.6398781630740393\n",
      "F1 for logistic regression is  0.009026434558349453\n",
      "precision and recall for Naive Bayes classifier 0 1 : 0.5732647814910026 0.14461738002594035\n",
      "f1 score for Naive Bayes classifiern is  0.23096841015018127\n",
      "accuracy for test data for logistic regression 3 1 is 0.6387066541705717\n",
      "F1 for logistic regression is  0.0\n",
      "precision and recall for Naive Bayes classifier 3 1 : 0.0 0.0\n",
      "f1 score for Naive Bayes classifiern is  0.0\n",
      "accuracy for test data for logistic regression is 0.6412839737582006\n",
      "F1 for logistic regression is  0.01796023091725465\n",
      "precision and recall for Naive Bayes classifier 1 1 : 0.5924855491329479 0.13294422827496757\n",
      "f1 score for Naive Bayes classifiern is  0.21716101694915252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "names = dataset.columns.values\n",
    "finaldf = pd.DataFrame(data=final,columns=names)\n",
    "\n",
    "np.random.seed(2018)\n",
    "train = np.random.choice([True, False], finaldf.shape[0], replace=True, p=[0.6, 0.4])\n",
    "\n",
    "\n",
    "personal_train = personal.iloc[train,:].as_matrix()\n",
    "personal_test = personal.iloc[~train,:].as_matrix()\n",
    "\n",
    "\n",
    "top = [0,3,1]\n",
    "#2 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        x_train = personal_train[:,[top[i],top[j]]].astype(float)\n",
    "        y_train = personal_train[:,7].astype(float)\n",
    "        \n",
    "        x_test = personal_test[:,[top[i],top[j]]].astype(float)\n",
    "        y_test = personal_test[:,7].astype(float)\n",
    "        \n",
    "        logit.fit(x_train, y_train)\n",
    "        y_test_pred = logit.predict(x_test)\n",
    "        \n",
    "        gnb.fit(x_train, y_train)\n",
    "        y_pred1 = gnb.predict(x_test)\n",
    "            \n",
    "        print('accuracy for test data for logistic regression',top[i],top[j],'is' , metrics.accuracy_score(y_test, y_test_pred))\n",
    "        print('F1 for logistic regression is ' , f1_score(y_test, y_test_pred))\n",
    "        \n",
    "        print('precision and recall for Naive Bayes classifier',top[i], top[j],':', metrics.precision_score(y_test, y_pred1), metrics.recall_score(y_test, y_pred1))\n",
    "        print('f1 score for Naive Bayes classifiern is ', f1_score(y_test,y_pred1))\n",
    "                \n",
    "#3 features\n",
    "x_train = personal_train[:,[0,3,1]].astype(float)\n",
    "y_train = personal_train[:,7].astype(float)\n",
    "\n",
    "x_test = personal_test[:,[0,3,2]].astype(float)\n",
    "y_test = personal_test[:,7].astype(float)\n",
    "\n",
    "logit.fit(x_train, y_train)\n",
    "y_test_pred = logit.predict(x_test)\n",
    "\n",
    "gnb.fit(x_train, y_train)\n",
    "y_pred1 = gnb.predict(x_test)\n",
    "\n",
    "print('accuracy for test data for logistic regression is' , metrics.accuracy_score(y_test, y_test_pred))\n",
    "print('F1 for logistic regression is ' , f1_score(y_test, y_test_pred))\n",
    "        \n",
    "print('precision and recall for Naive Bayes classifier',top[i], top[j],':', metrics.precision_score(y_test, y_pred1), metrics.recall_score(y_test, y_pred1))\n",
    "print('f1 score for Naive Bayes classifiern is ', f1_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 1 0 3\n",
      "Accuracy score for RBF SVM with 2 features is  0.8420805998125586\n",
      "F1 score for RBF SVM with 2 features is  0.0\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      1.00      0.91      3594\n",
      "        1.0       0.00      0.00      0.00       674\n",
      "\n",
      "avg / total       0.71      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 10 0 3\n",
      "Accuracy score for RBF SVM with 2 features is  0.837863167760075\n",
      "F1 score for RBF SVM with 2 features is  0.011428571428571429\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.99      0.91      3594\n",
      "        1.0       0.15      0.01      0.01       674\n",
      "\n",
      "avg / total       0.73      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 100 0 3\n",
      "Accuracy score for RBF SVM with 2 features is  0.837863167760075\n",
      "F1 score for RBF SVM with 2 features is  0.011428571428571429\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.99      0.91      3594\n",
      "        1.0       0.15      0.01      0.01       674\n",
      "\n",
      "avg / total       0.73      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 1 0 1\n",
      "Accuracy score for RBF SVM with 2 features is  0.8420805998125586\n",
      "F1 score for RBF SVM with 2 features is  0.0\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      1.00      0.91      3594\n",
      "        1.0       0.00      0.00      0.00       674\n",
      "\n",
      "avg / total       0.71      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 10 0 1\n",
      "Accuracy score for RBF SVM with 2 features is  0.8371602624179943\n",
      "F1 score for RBF SVM with 2 features is  0.008559201141226819\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.99      0.91      3594\n",
      "        1.0       0.11      0.00      0.01       674\n",
      "\n",
      "avg / total       0.73      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 100 0 1\n",
      "Accuracy score for RBF SVM with 2 features is  0.8371602624179943\n",
      "F1 score for RBF SVM with 2 features is  0.008559201141226819\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.99      0.91      3594\n",
      "        1.0       0.11      0.00      0.01       674\n",
      "\n",
      "avg / total       0.73      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 1 3 1\n",
      "Accuracy score for RBF SVM with 2 features is  0.8420805998125586\n",
      "F1 score for RBF SVM with 2 features is  0.0\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      1.00      0.91      3594\n",
      "        1.0       0.00      0.00      0.00       674\n",
      "\n",
      "avg / total       0.71      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 10 3 1\n",
      "Accuracy score for RBF SVM with 2 features is  0.8409090909090909\n",
      "F1 score for RBF SVM with 2 features is  0.0029368575624082235\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      1.00      0.91      3594\n",
      "        1.0       0.14      0.00      0.00       674\n",
      "\n",
      "avg / total       0.73      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 100 3 1\n",
      "Accuracy score for RBF SVM with 2 features is  0.8409090909090909\n",
      "F1 score for RBF SVM with 2 features is  0.0029368575624082235\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      1.00      0.91      3594\n",
      "        1.0       0.14      0.00      0.00       674\n",
      "\n",
      "avg / total       0.73      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [0,3,1]\n",
    "\n",
    "#RBF Kernel\n",
    "    \n",
    "#2 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        x_train = personal_train[:,[top[i],top[j]]].astype(float)\n",
    "        y_train = personal_train[:,6].astype(float)\n",
    "\n",
    "        x_test = personal_test[:,[top[i],top[j]]].astype(float)\n",
    "        y_test = personal_test[:,6].astype(float)\n",
    "\n",
    "        clf=[]\n",
    "        for C in [1,10,100]:\n",
    "            \n",
    "            clf = svm.SVC(kernel='rbf', C=C)\n",
    "            clf.fit(x_train, y_train)\n",
    "            predicted = clf.predict(x_test)\n",
    "            print(\"Prediction for RBF SVM - C value {1} for features {2} and {3}\", C,top[i],top[j])\n",
    "            \n",
    "            print (\"Accuracy score for RBF SVM with 2 features is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "            print (\"F1 score for RBF SVM with 2 features is \" ,metrics.f1_score(y_test, predicted))\n",
    "            print(\"Classification report for RBF SVM with 2 features: \",classification_report(y_test, predicted))\n",
    "            print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for RBF SVM with 3 features is  0.8409090909090909\n",
      "F1 score for RBF SVM with 3 features is  0.0\n",
      "Classification report for RBF SVM with 3 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      1.00      0.91      3594\n",
      "        1.0       0.00      0.00      0.00       674\n",
      "\n",
      "avg / total       0.71      0.84      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 3 features is  0.8256794751640113\n",
      "F1 score for RBF SVM with 3 features is  0.05583756345177665\n",
      "Classification report for RBF SVM with 3 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.97      0.90      3594\n",
      "        1.0       0.19      0.03      0.06       674\n",
      "\n",
      "avg / total       0.74      0.83      0.77      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 3 features is  0.8149015932521088\n",
      "F1 score for RBF SVM with 3 features is  0.08986175115207373\n",
      "Classification report for RBF SVM with 3 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.84      0.96      0.90      3594\n",
      "        1.0       0.20      0.06      0.09       674\n",
      "\n",
      "avg / total       0.74      0.81      0.77      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [0,3,1]\n",
    "\n",
    "#RBF Kernel\n",
    "    \n",
    "#3 features:\n",
    "\n",
    "x_train = personal_train[:,[0,3,1]].astype(float)\n",
    "y_train = personal_train[:,6].astype(float)\n",
    "\n",
    "x_test = personal_test[:,[0,3,1]].astype(float)\n",
    "y_test = personal_test[:,6].astype(float)\n",
    "\n",
    "clf=[]\n",
    "for C in [1,10,100]:\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=C)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "   \n",
    "    print (\"Accuracy score for RBF SVM with 3 features is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "    print (\"F1 score for RBF SVM with 3 features is \" ,metrics.f1_score(y_test, predicted))\n",
    "    print(\"Classification report for RBF SVM with 3 features: \",classification_report(y_test, predicted))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "contact = finaldf.copy()\n",
    "contact.drop(['age','job','marital','education','default','housing','loan','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed'],axis=1,inplace=True)\n",
    "#print(contact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters using grid search: \n",
      " {'bootstrap': True, 'criterion': 'entropy', 'max_depth': 2, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "x=contact.iloc[:,:-1]\n",
    "y=contact.iloc[:,-1]\n",
    "fit_rf=RandomForestClassifier(random_state=0)\n",
    "\n",
    "np.random.seed(0)\n",
    "param_dist = {'max_depth':[2,3,4],\n",
    "             'bootstrap':[True, False],\n",
    "             'max_features':['auto','sqrt','log2',None],\n",
    "             'criterion':['gini','entropy']}\n",
    "\n",
    "cv_rf = GridSearchCV(fit_rf,cv=10,param_grid=param_dist,n_jobs=3)\n",
    "\n",
    "cv_rf.fit(x,y)\n",
    "\n",
    "print('Best parameters using grid search: \\n',\n",
    "     cv_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. The feature pdays with index 4 has a mean decrease in impurity of 0.33236\n",
      "2. The feature poutcome with index 6 has a mean decrease in impurity of 0.27579\n",
      "3. The feature contact with index 0 has a mean decrease in impurity of 0.13295\n",
      "4. The feature previous with index 5 has a mean decrease in impurity of 0.12380\n",
      "5. The feature month with index 1 has a mean decrease in impurity of 0.10379\n",
      "6. The feature campaign with index 3 has a mean decrease in impurity of 0.02848\n",
      "7. The feature day_of_week with index 2 has a mean decrease in impurity of 0.00283\n"
     ]
    }
   ],
   "source": [
    "fit_rf.set_params(criterion='entropy',n_estimators = 100,max_features='auto',max_depth=2,bootstrap=False)\n",
    "fit_rf.fit(x,y)\n",
    "\n",
    "def variable_importance(fit):\n",
    "    importances = fit.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    return {'importance':importances,'index':indices}\n",
    "\n",
    "var_imp_rf=variable_importance(fit_rf)\n",
    "importances_rf=var_imp_rf['importance']\n",
    "indices_rf=var_imp_rf['index']\n",
    "\n",
    "print('Feature ranking:')\n",
    "feature_name=['contact','month','day_of_week','campaign','pdays','previous','poutcome']\n",
    "\n",
    "\n",
    "for i in range(0,indices_rf.shape[0]):\n",
    "    f = i\n",
    "    print('{0}. The feature {1} with index {3} has a mean decrease in impurity of {2:.5f}'.format(f+1,feature_name[indices_rf[i]],importances_rf[indices_rf[f]],indices_rf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for test data for logistic regression 4 6 is 0.7087628865979382\n",
      "F1 for logistic regression is  0.3481908757210278\n",
      "precision and recall for Naive Bayes classifier 4 6 : 0.9095890410958904 0.21530479896238652\n",
      "f1 score for Naive Bayes classifiern is  0.3481908757210278\n",
      "accuracy for test data for logistic regression 4 0 is 0.7087628865979382\n",
      "F1 for logistic regression is  0.3481908757210278\n",
      "precision and recall for Naive Bayes classifier 4 0 : 0.9095890410958904 0.21530479896238652\n",
      "f1 score for Naive Bayes classifiern is  0.3481908757210278\n",
      "accuracy for test data for logistic regression 6 0 is 0.6986879100281163\n",
      "F1 for logistic regression is  0.30561555075593955\n",
      "precision and recall for Naive Bayes classifier 6 0 : 0.625 0.321011673151751\n",
      "f1 score for Naive Bayes classifiern is  0.42416452442159386\n",
      "accuracy for test data for logistic regression is 0.7087628865979382\n",
      "F1 for logistic regression is  0.3481908757210278\n",
      "precision and recall for Naive Bayes classifier 0 0 : 0.9095890410958904 0.21530479896238652\n",
      "f1 score for Naive Bayes classifiern is  0.3481908757210278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "names = dataset.columns.values\n",
    "finaldf = pd.DataFrame(data=final,columns=names)\n",
    "\n",
    "np.random.seed(2018)\n",
    "train = np.random.choice([True, False], finaldf.shape[0], replace=True, p=[0.6, 0.4])\n",
    "\n",
    "\n",
    "contact_train = contact.iloc[train,:].as_matrix()\n",
    "contact_test = contact.iloc[~train,:].as_matrix()\n",
    "\n",
    "\n",
    "top = [4,6,0]\n",
    "#2 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        x_train = contact_train[:,[top[i],top[j]]].astype(float)\n",
    "        y_train = contact_train[:,7].astype(float)\n",
    " \n",
    "        x_test = contact_test[:,[top[i],top[j]]].astype(float)\n",
    "        y_test = contact_test[:,7].astype(float)\n",
    "        \n",
    "        logit.fit(x_train, y_train)\n",
    "        y_test_pred = logit.predict(x_test)\n",
    "        \n",
    "        gnb.fit(x_train, y_train)\n",
    "        y_pred1 = gnb.predict(x_test)\n",
    "\n",
    "        print('accuracy for test data for logistic regression',top[i],top[j],'is' , metrics.accuracy_score(y_test, y_test_pred))\n",
    "        print('F1 for logistic regression is ' , f1_score(y_test, y_test_pred))\n",
    "\n",
    "        print('precision and recall for Naive Bayes classifier',top[i], top[j],':', metrics.precision_score(y_test, y_pred1), metrics.recall_score(y_test, y_pred1))\n",
    "        print('f1 score for Naive Bayes classifiern is ', f1_score(y_test,y_pred1))\n",
    "        \n",
    "#3 features\n",
    "x_train = contact_train[:,[4,6,0]].astype(float)\n",
    "y_train = contact_train[:,7].astype(float)\n",
    "\n",
    "x_test = contact_test[:,[4,6,0]].astype(float)\n",
    "y_test = contact_test[:,7].astype(float)\n",
    "\n",
    "logit.fit(x_train, y_train)\n",
    "y_test_pred = logit.predict(x_test)\n",
    "\n",
    "gnb.fit(x_train, y_train)\n",
    "y_pred1 = gnb.predict(x_test)\n",
    "\n",
    "print('accuracy for test data for logistic regression is' , metrics.accuracy_score(y_test, y_test_pred))\n",
    "print('F1 for logistic regression is ' , f1_score(y_test, y_test_pred))\n",
    "\n",
    "print('precision and recall for Naive Bayes classifier',top[i], top[j],':', metrics.precision_score(y_test, y_pred1), metrics.recall_score(y_test, y_pred1))\n",
    "print('f1 score for Naive Bayes classifiern is ', f1_score(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on contact dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 1 4 6\n",
      "Accuracy score for RBF SVM with 2 features is  0.7082942830365511\n",
      "F1 score for RBF SVM with 2 features is  0.34645669291338577\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.21      0.35      1542\n",
      "\n",
      "avg / total       0.77      0.71      0.64      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 10 4 6\n",
      "Accuracy score for RBF SVM with 2 features is  0.7082942830365511\n",
      "F1 score for RBF SVM with 2 features is  0.34645669291338577\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.21      0.35      1542\n",
      "\n",
      "avg / total       0.77      0.71      0.64      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 100 4 6\n",
      "Accuracy score for RBF SVM with 2 features is  0.7082942830365511\n",
      "F1 score for RBF SVM with 2 features is  0.34645669291338577\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.21      0.35      1542\n",
      "\n",
      "avg / total       0.77      0.71      0.64      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 1 4 0\n",
      "Accuracy score for RBF SVM with 2 features is  0.7087628865979382\n",
      "F1 score for RBF SVM with 2 features is  0.3481908757210278\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.22      0.35      1542\n",
      "\n",
      "avg / total       0.77      0.71      0.64      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 10 4 0\n",
      "Accuracy score for RBF SVM with 2 features is  0.7078256794751641\n",
      "F1 score for RBF SVM with 2 features is  0.34471886495007886\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.21      0.34      1542\n",
      "\n",
      "avg / total       0.77      0.71      0.64      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 100 4 0\n",
      "Accuracy score for RBF SVM with 2 features is  0.7078256794751641\n",
      "F1 score for RBF SVM with 2 features is  0.34471886495007886\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.21      0.34      1542\n",
      "\n",
      "avg / total       0.77      0.71      0.64      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 1 6 0\n",
      "Accuracy score for RBF SVM with 2 features is  0.7026710402999062\n",
      "F1 score for RBF SVM with 2 features is  0.3224773091297384\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.20      0.32      1542\n",
      "\n",
      "avg / total       0.77      0.70      0.63      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 10 6 0\n",
      "Accuracy score for RBF SVM with 2 features is  0.7026710402999062\n",
      "F1 score for RBF SVM with 2 features is  0.3224773091297384\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.20      0.32      1542\n",
      "\n",
      "avg / total       0.77      0.70      0.63      4268\n",
      "\n",
      "\n",
      "\n",
      "Prediction for RBF SVM - C value {1} for features {2} and {3} 100 6 0\n",
      "Accuracy score for RBF SVM with 2 features is  0.7026710402999062\n",
      "F1 score for RBF SVM with 2 features is  0.3224773091297384\n",
      "Classification report for RBF SVM with 2 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.69      0.99      0.81      2726\n",
      "        1.0       0.91      0.20      0.32      1542\n",
      "\n",
      "avg / total       0.77      0.70      0.63      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [4,6,0]\n",
    "\n",
    "#RBF Kernel\n",
    "\n",
    "    \n",
    "#2 features:\n",
    "for i in range(3):\n",
    "    for j in range(i+1,3):\n",
    "        x_train = contact_train[:,[top[i],top[j]]].astype(float)\n",
    "        y_train = contact_train[:,7].astype(float)\n",
    "\n",
    "        x_test = contact_test[:,[top[i],top[j]]].astype(float)\n",
    "        y_test = contact_test[:,7].astype(float)\n",
    "\n",
    "        clf=[]\n",
    "        for C in [1,10,100]:\n",
    "            \n",
    "            clf = svm.SVC(kernel='rbf', C=C)\n",
    "            clf.fit(x_train, y_train)\n",
    "            predicted = clf.predict(x_test)\n",
    "            print(\"Prediction for RBF SVM - C value {1} for features {2} and {3}\", C,top[i],top[j])\n",
    "            \n",
    "            print (\"Accuracy score for RBF SVM with 2 features is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "            print (\"F1 score for RBF SVM with 2 features is \" ,metrics.f1_score(y_test, predicted))\n",
    "            print(\"Classification report for RBF SVM with 2 features: \",classification_report(y_test, predicted))\n",
    "            print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for RBF SVM with 3 features is  0.7162605435801312\n",
      "F1 score for RBF SVM with 3 features is  0.0\n",
      "Classification report for RBF SVM with 3 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      1.00      0.83      3057\n",
      "        1.0       0.00      0.00      0.00      1211\n",
      "\n",
      "avg / total       0.51      0.72      0.60      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for RBF SVM with 3 features is  0.7157919400187441\n",
      "F1 score for RBF SVM with 3 features is  0.0\n",
      "Classification report for RBF SVM with 3 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      1.00      0.83      3057\n",
      "        1.0       0.00      0.00      0.00      1211\n",
      "\n",
      "avg / total       0.51      0.72      0.60      4268\n",
      "\n",
      "\n",
      "\n",
      "Accuracy score for RBF SVM with 3 features is  0.7155576382380506\n",
      "F1 score for RBF SVM with 3 features is  0.0\n",
      "Classification report for RBF SVM with 3 features:               precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      1.00      0.83      3057\n",
      "        1.0       0.00      0.00      0.00      1211\n",
      "\n",
      "avg / total       0.51      0.72      0.60      4268\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top = [4,6,0]\n",
    "\n",
    "#rbf Kernel\n",
    "    \n",
    "#3 features:\n",
    "\n",
    "x_train = bank_train[:,[4,6,0]].astype(float)\n",
    "y_train = bank_train[:,7].astype(float)\n",
    "\n",
    "x_test = bank_test[:,[4,6,0]].astype(float)\n",
    "y_test = bank_test[:,7].astype(float)\n",
    "\n",
    "clf=[]\n",
    "for C in [1,10,100]:\n",
    "    clf = svm.SVC(kernel='rbf', C=C)\n",
    "    clf.fit(x_train, y_train)\n",
    "    predicted = clf.predict(x_test)\n",
    "    \n",
    "    print (\"Accuracy score for RBF SVM with 3 features is \" ,metrics.accuracy_score(y_test, predicted))\n",
    "    print (\"F1 score for RBF SVM with 3 features is \" ,metrics.f1_score(y_test, predicted))\n",
    "    print(\"Classification report for RBF SVM with 3 features: \",classification_report(y_test, predicted))\n",
    "    print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>poutcome_0.0</th>\n",
       "      <th>poutcome_1.0</th>\n",
       "      <th>poutcome_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   contact  month  day_of_week  campaign  pdays  previous    y  poutcome_0.0  \\\n",
       "0      1.0    6.0          1.0       1.0  999.0       0.0  0.0             0   \n",
       "1      1.0    6.0          1.0       1.0  999.0       0.0  0.0             0   \n",
       "2      1.0    6.0          1.0       1.0  999.0       0.0  0.0             0   \n",
       "3      1.0    6.0          1.0       1.0  999.0       0.0  0.0             0   \n",
       "4      1.0    6.0          1.0       1.0  999.0       0.0  0.0             0   \n",
       "\n",
       "   poutcome_1.0  poutcome_2.0  \n",
       "0             1             0  \n",
       "1             1             0  \n",
       "2             1             0  \n",
       "3             1             0  \n",
       "4             1             0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert nominal values using pd.get_dummies\n",
    "def dummify_dataset(df, column):       \n",
    "    df = pd.concat([df, pd.get_dummies(df[column], prefix=column)],axis=1)\n",
    "    df = df.drop([column], axis=1)\n",
    "    return df\n",
    "\n",
    "columns_to_dummify = ['poutcome']\n",
    "for column in columns_to_dummify:\n",
    "    contact = dummify_dataset(contact, column)\n",
    "    \n",
    "contact.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dataset.columns.values\n",
    "finaldf = pd.DataFrame(data=final,    # values\n",
    "                      columns=names)\n",
    "\n",
    "np.random.seed(2018)\n",
    "train = np.random.choice([True, False], finaldf.shape[0], replace=True, p=[0.6, 0.4])\n",
    "\n",
    "\n",
    "contact_train = contact.iloc[train,:]\n",
    "contact_test = contact.iloc[~train,:]"
   ]
  },
  
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = contact_train.iloc[:,[0,1,2,3,4,5,7,8,9]].astype(float)\n",
    "y_train = contact_train.iloc[:,6].astype(float)\n",
    "\n",
    "x_test = contact_test.iloc[:,[0,1,2,3,4,5,7,8,9]].astype(float)\n",
    "y_test = contact_test.iloc[:,6].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = []\n",
    "#for C in [1, 10, 100, 1000]:\n",
    "for C in [100]:\n",
    "    clf.append(svm.LinearSVC(C=C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "0.7085285848172446\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    clf[i].fit(x_train, y_train)\n",
    "    predicted = clf[i].predict(x_test)\n",
    "    print(predicted)\n",
    "    print (metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=[]\n",
    "for C in [10]:\n",
    "    clf.append(svm.SVC(kernel='linear', C=C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "0.7087628865979382\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    clf[i].fit(x_train, y_train)\n",
    "    predicted = clf[i].predict(x_test)\n",
    "    print(predicted)\n",
    "    print (metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "0.7521087160262419\n"
     ]
    }
   ],
   "source": [
    "clf = []\n",
    "for kern in ['rbf']:\n",
    "    clf.append(svm.SVC(kernel=kern, gamma=1))\n",
    "\n",
    "for i in range(1):\n",
    "    clf[i].fit(x_train, y_train)\n",
    "    predicted = clf[i].predict(x_test)\n",
    "    print(predicted)\n",
    "    print (metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on top 2 features - previous outcome and contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = contact_train.iloc[:,[0,1,2,3]].astype(float)\n",
    "y_train = contact_train.iloc[:,6].astype(float)\n",
    "\n",
    "x_test = contact_test.iloc[:,[0,1,2,3]].astype(float)\n",
    "y_test = contact_test.iloc[:,6].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.6387066541705717\n"
     ]
    }
   ],
   "source": [
    "#Linear Kernel\n",
    "\n",
    "clf=[]\n",
    "for C in [10]:\n",
    "    clf.append(svm.SVC(kernel='linear', C=C))\n",
    "\n",
    "for i in range(1):\n",
    "    clf[i].fit(x_train, y_train)\n",
    "    predicted = clf[i].predict(x_test)\n",
    "    print(predicted)\n",
    "    print (metrics.accuracy_score(y_test, predicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0.7216494845360825\n"
     ]
    }
   ],
   "source": [
    "#rbf kernel\n",
    "\n",
    "clf = []\n",
    "for kern in ['rbf']:\n",
    "    clf.append(svm.SVC(kernel=kern, gamma=1))\n",
    "\n",
    "for i in range(1):\n",
    "    clf[i].fit(x_train, y_train)\n",
    "    predicted = clf[i].predict(x_test)\n",
    "    print(predicted)\n",
    "    print (metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM on  2 features - pdays and contact¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = contact_train.iloc[:,[0,4]].astype(float)\n",
    "y_train = contact_train.iloc[:,6].astype(float)\n",
    "\n",
    "x_test = contact_test.iloc[:,[0,4]].astype(float)\n",
    "y_test = contact_test.iloc[:,6].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "0.7087628865979382\n"
     ]
    }
   ],
   "source": [
    "#Linear Kernel\n",
    "\n",
    "clf=[]\n",
    "for C in [10]:\n",
    "    clf.append(svm.SVC(kernel='linear', C=C))\n",
    "\n",
    "for i in range(1):\n",
    "    clf[i].fit(x_train, y_train)\n",
    "    predicted = clf[i].predict(x_test)\n",
    "    print(predicted)\n",
    "    print (metrics.accuracy_score(y_test, predicted))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 1. 0. 0.]\n",
      "0.7087628865979382\n"
     ]
    }
   ],
   "source": [
    "#rbf kernel\n",
    "\n",
    "clf = []\n",
    "for kern in ['rbf']:\n",
    "    clf.append(svm.SVC(kernel=kern, gamma=1))\n",
    "\n",
    "for i in range(1):\n",
    "    clf[i].fit(x_train, y_train)\n",
    "    predicted = clf[i].predict(x_test)\n",
    "    print(predicted)\n",
    "    print (metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
